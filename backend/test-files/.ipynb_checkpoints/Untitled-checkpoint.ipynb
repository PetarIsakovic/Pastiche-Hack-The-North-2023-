{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e314f9d3-2dac-43f9-8be9-9a89a291603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, time\n",
    "import torch\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d82dab8-d6c3-4f6d-8ad7-486a52e5f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/wiki-art loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "ds = deeplake.load('hub://activeloop/wiki-art')\n",
    "dataloader = ds.pytorch(num_workers=0, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b1c4ee-5be0-4752-ad9f-fb1d0861d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"90%\"\n",
       "            height=\"800\"\n",
       "            src=\"https://app.activeloop.ai/visualizer/hub?url=hub://activeloop/wiki-art&token=eyJhbGciOiJIUzUxMiIsImlhdCI6MTY5NDg3OTMzMSwiZXhwIjoxNjk4NDc5MzMxfQ.eyJpZCI6InB1YmxpYyJ9.6HdjwPnGNP6EX38PxQbjBr4qF_HZmP9x8e0eqoMSHwuVGEFb-MsaZO0AZdP2vBvcWjfkv6lr9Fu4zNKpJuBqJg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8321473910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = ds.images[0].numpy() \n",
    "labels = ds.labels[0].data()\n",
    "                                               # them as a list of numpy arrays\n",
    "img_list = ds.labels[0:100].numpy(aslist=True) # Fetch 100 labels and store \n",
    "img_list\n",
    "labels_list = ds.labels.info['class_names']\n",
    "ds.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8ceba4-b30e-4527-a51b-7b21779d9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/fashion-mnist-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/fashion-mnist-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/fashion-mnist-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/fashion-mnist-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "ds_train = deeplake.load('hub://activeloop/fashion-mnist-train')\n",
    "ds_test = deeplake.load('hub://activeloop/fashion-mnist-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4472ee1-4f1e-40a8-80be-9bb4d4c7852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = transforms.Compose([\n",
    "    transforms.RandomRotation(20), # Image augmentation\n",
    "    transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9ed07e-f7f2-4be4-94a6-f1606b27957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Since torchvision transforms expect PIL images, we use the 'pil' decode_method for the 'images' tensor. This is much faster than running ToPILImage inside the transform\n",
    "train_loader = ds_train.pytorch(num_workers = 0, shuffle = True, transform = {'images': tform, 'labels': None}, batch_size = batch_size, decode_method = {'images': 'pil'})\n",
    "test_loader = ds_test.pytorch(num_workers = 0, transform = {'images': tform, 'labels': None}, batch_size = batch_size, decode_method = {'images': 'pil'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84b2b11-2aa4-4875-8504-5fe7d5d2dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8547a0d8-aa91-42a3-8c52-04d4b17fc713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaryan/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aaryan/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/aaryan/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:01<00:00, 39.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Use a pre-trained ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Convert model to grayscale\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Update the fully connected layer based on the number of classes in the dataset\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, len(ds_train.labels.info.class_names))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Specity the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8193f3d-4f10-490b-84ed-45def1470416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Zero the performance stats for each epoch\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['images']\n",
    "        labels = torch.squeeze(data['labels'])\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "    \n",
    "        # Print performance statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 0:    # print every 10 batches\n",
    "            batch_time = time.time()\n",
    "            speed = (i+1)/(batch_time-start_time)\n",
    "            print('[%5d] loss: %.3f, speed: %.2f, accuracy: %.2f %%' %\n",
    "                  (i, running_loss, speed, accuracy))\n",
    "\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "    \n",
    "def test_model(model, data_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data['images']\n",
    "            labels = torch.squeeze(data['labels'])\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.float())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "            \n",
    "        print('Finished Testing')\n",
    "        print('Testing accuracy: %.1f %%' %(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d80470-5880-41a3-b5aa-5c3422a29dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Training Epoch 1 ------------------\n",
      "[    0] loss: 2.692, speed: 0.31, accuracy: 1.56 %\n",
      "[   10] loss: 25.133, speed: 1.73, accuracy: 10.47 %\n",
      "[   20] loss: 21.820, speed: 2.21, accuracy: 19.53 %\n",
      "[   30] loss: 20.106, speed: 2.44, accuracy: 27.66 %\n",
      "[   40] loss: 19.241, speed: 2.57, accuracy: 33.12 %\n",
      "[   50] loss: 17.833, speed: 2.63, accuracy: 38.28 %\n",
      "[   60] loss: 16.618, speed: 2.70, accuracy: 44.22 %\n",
      "[   70] loss: 15.786, speed: 2.74, accuracy: 45.62 %\n",
      "[   80] loss: 14.320, speed: 2.77, accuracy: 53.12 %\n",
      "[   90] loss: 13.612, speed: 2.80, accuracy: 52.50 %\n",
      "[  100] loss: 13.216, speed: 2.81, accuracy: 57.50 %\n",
      "[  110] loss: 13.083, speed: 2.82, accuracy: 55.31 %\n",
      "[  120] loss: 11.823, speed: 2.83, accuracy: 61.41 %\n",
      "[  130] loss: 11.809, speed: 2.84, accuracy: 59.53 %\n",
      "[  140] loss: 11.895, speed: 2.85, accuracy: 61.41 %\n",
      "[  150] loss: 11.150, speed: 2.84, accuracy: 63.12 %\n",
      "[  160] loss: 10.880, speed: 2.84, accuracy: 62.34 %\n",
      "[  170] loss: 10.284, speed: 2.86, accuracy: 63.91 %\n",
      "[  180] loss: 10.193, speed: 2.86, accuracy: 66.09 %\n",
      "[  190] loss: 10.242, speed: 2.86, accuracy: 63.75 %\n",
      "[  200] loss: 10.157, speed: 2.88, accuracy: 67.03 %\n",
      "[  210] loss: 9.837, speed: 2.88, accuracy: 66.41 %\n",
      "[  220] loss: 9.661, speed: 2.89, accuracy: 65.62 %\n",
      "[  230] loss: 9.777, speed: 2.88, accuracy: 66.56 %\n",
      "[  240] loss: 9.280, speed: 2.89, accuracy: 68.91 %\n",
      "[  250] loss: 9.269, speed: 2.85, accuracy: 67.81 %\n",
      "[  260] loss: 9.981, speed: 2.82, accuracy: 66.25 %\n",
      "[  270] loss: 9.095, speed: 2.82, accuracy: 66.41 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print(\"------------------ Training Epoch {} ------------------\".format(epoch+1))\n",
    "    train_one_epoch(model, optimizer, train_loader, device)\n",
    "\n",
    "    test_model(model, test_loader)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2099a38-4981-4beb-818c-5dd853f0d083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
